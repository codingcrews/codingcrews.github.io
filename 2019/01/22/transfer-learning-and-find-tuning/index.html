<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>딥러닝으로 개와 고양이를 분류해보자 - 전이학습과 미세조정 | CodingCrew</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="MLKeras딥러닝으로 시리즈CNN">
  
  
    <meta name="google-site-verification" content="2YVImY1fo1thQTx-sHmMQhhE7x9aoPG7F593q2qt734">
  
  
  
  
    <meta name="naver-site-verification" content="6e851ae0213de51257ab8801ac88ee25b5581313">
  
  <meta name="description" content="Transfer Learning &amp;amp; Find Tuning안녕하세요.이번 시간은 학습된 모델을 우리의 도메인에 맞춰 사용할 수 있도록 변경하는법을 알아봅시다.저번 포스팅에서 개와 고양이를 분류하는 CNN 모델을 만들어보고 학습을 진행해봤는데요.ResNet50 모델의 경우 모델이 무거운데다 저희의 학습 데이터량도 많지 않고(증식을 이용하긴 했으나, 과적">
<meta name="keywords" content="ML,Keras,딥러닝으로 시리즈,CNN">
<meta property="og:type" content="article">
<meta property="og:title" content="딥러닝으로 개와 고양이를 분류해보자 - 전이학습과 미세조정">
<meta property="og:url" content="https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/index.html">
<meta property="og:site_name" content="CodingCrew">
<meta property="og:description" content="Transfer Learning &amp;amp; Find Tuning안녕하세요.이번 시간은 학습된 모델을 우리의 도메인에 맞춰 사용할 수 있도록 변경하는법을 알아봅시다.저번 포스팅에서 개와 고양이를 분류하는 CNN 모델을 만들어보고 학습을 진행해봤는데요.ResNet50 모델의 경우 모델이 무거운데다 저희의 학습 데이터량도 많지 않고(증식을 이용하긴 했으나, 과적">
<meta property="og:locale" content="ko">
<meta property="og:image" content="https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_16_0.png">
<meta property="og:image" content="https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_17_0.png">
<meta property="og:image" content="https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_33_0.png">
<meta property="og:image" content="https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_34_0.png">
<meta property="og:updated_time" content="2019-01-29T18:18:06.390Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="딥러닝으로 개와 고양이를 분류해보자 - 전이학습과 미세조정">
<meta name="twitter:description" content="Transfer Learning &amp;amp; Find Tuning안녕하세요.이번 시간은 학습된 모델을 우리의 도메인에 맞춰 사용할 수 있도록 변경하는법을 알아봅시다.저번 포스팅에서 개와 고양이를 분류하는 CNN 모델을 만들어보고 학습을 진행해봤는데요.ResNet50 모델의 경우 모델이 무거운데다 저희의 학습 데이터량도 많지 않고(증식을 이용하긴 했으나, 과적">
<meta name="twitter:image" content="https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_16_0.png">
  
    <link rel="alternate" href="/atom.xml" title="CodingCrew" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/logo.png">
  <link rel="apple-touch-icon" href="/css/images/logo.png">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css">
  

  

  

</head>
</html>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;" href="#" data-toggle="modal" data-target="#myModal">
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/logo.png">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </ul></div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-transfer-learning-and-find-tuning" style="width: 75%; float:left;" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      딥러닝으로 개와 고양이를 분류해보자 - 전이학습과 미세조정
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2019/01/22/transfer-learning-and-find-tuning/" class="article-date">
	  <time datetime="2019-01-22T09:29:03.000Z" itemprop="datePublished">2019-01-22</time>
	</a>

      
    <a class="article-category-link" href="/categories/ml/">ML</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Transfer-Learning-amp-Find-Tuning"><a href="#Transfer-Learning-amp-Find-Tuning" class="headerlink" title="Transfer Learning &amp; Find Tuning"></a>Transfer Learning &amp; Find Tuning</h1><p>안녕하세요.<br>이번 시간은 학습된 모델을 우리의 도메인에 맞춰 사용할 수 있도록 변경하는법을 알아봅시다.<br>저번 포스팅에서 개와 고양이를 분류하는 CNN 모델을 만들어보고 학습을 진행해봤는데요.<br>ResNet50 모델의 경우 모델이 무거운데다 저희의 학습 데이터량도 많지 않고(증식을 이용하긴 했으나, 과적합될 가능성이 존재),<br>학습시간도 모자랐었습니다. (32에폭 도는데 대략 40분정도의 시간이 소요됨. 대회에 나간 모델의 경우 2~3주동안 학습을 진행했다고 함.)  </p>
<p>그럼 매번 모델을 만들때마다 새로 학습을 진행해야 할까요 ?<br>개와 고양이의 분류 모델을 만드는데 2주,<br>개, 고양이와 거북이를 분류하는 모델을 다시 만드는데 2주… 이렇게 시간이 소요될 수 있습니다.  </p>
<p>저희가 사용한 모델들은 CNN 레이어는 이미지의 특징들을 뽑아내주고,<br>마지막 Fully Connected 레이어에서 그 해당 특징들을 기반으로 분류를 하는 형태를 띄는데요.<br>그럼 기존에 학습된 모델을 가지고 특징을 추출하여 FC레이어만 새로 재학습을 할수는 없을까요 ?  </p>
<p>오늘은 InceptionV3 모델을 이용하여 Feature Extraction, Transfer Learning을 진행해보도록 하겠습니다.</p>
<h1 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h1><p>어파인 레이어(Fully Connected Layer)를 거치기 바로 직전의 추상화된 레이어의 특징들을 보틀넥 피쳐라 말합니다.<br>저희는 기존 imagenet 데이터셋을 기반으로 학습된 모델을 사용하여, 이미지의 특징을 추출하고,<br>이 특징을 기반으로 FC레이어를 분류시킬 수 있는 모델을 만들어 보도록 하겠습니다.<br>이 과정을 <strong>Feature Extraction</strong> 혹은 <strong>Transfer Learning</strong>이라고 말하기도 합니다.  </p>
<p>이 예제는 마지막 분류 레이어만 학습을 진행해도 되기 때문에 CPU로도 빠른 속도로 학습이 가능합니다.<br>이 뒤의 Fine Tuning시에는 GPU가 아닐경우 많은 시간이 소요되니 GPU 환경을 권장합니다.<br><del>(피쳐 추출 부분에서 시간이 많이 소요되는건 비밀..)</del>  </p>
<h2 id="데이터셋-준비"><a href="#데이터셋-준비" class="headerlink" title="데이터셋 준비"></a>데이터셋 준비</h2><p>데이터셋은 이전 포스팅에서 이용한 개, 고양이 데이터셋을 이용합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 위노그라드 알고리즘 설정 (GPU 사용시 conv 연산이 빨라짐)</span></span><br><span class="line">os.environ[<span class="string">'TF_ENABLE_WINOGRAD_NONFUSED'</span>] = <span class="string">'1'</span></span><br><span class="line"></span><br><span class="line">rootPath = <span class="string">'./datasets/cat-and-dog'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미지의 사이즈는 논문에서는 (224, 224, 3)을 사용하여, 빠른 학습을 위해 사이즈를 조정</span></span><br><span class="line">IMG_SIZE = (<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)  </span><br><span class="line"></span><br><span class="line">imageGenerator = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">20</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    brightness_range=[<span class="number">.2</span>, <span class="number">.2</span>],</span><br><span class="line">    horizontal_flip=<span class="keyword">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainGen = imageGenerator.flow_from_directory(</span><br><span class="line">    os.path.join(rootPath, <span class="string">'training_set'</span>),</span><br><span class="line">    target_size=IMG_SIZE[:<span class="number">2</span>],</span><br><span class="line">    batch_size=<span class="number">20</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">testGen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">).flow_from_directory(</span><br><span class="line">    os.path.join(rootPath, <span class="string">'test_set'</span>),</span><br><span class="line">    target_size=IMG_SIZE[:<span class="number">2</span>],</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Found 8005 images belonging to 2 classes.
Found 2023 images belonging to 2 classes.
</code></pre><h2 id="모델-구성"><a href="#모델-구성" class="headerlink" title="모델 구성"></a>모델 구성</h2><p>모델은 피쳐추출기로 사용할 InceptionV3 모델과 이를 분류할 분류기 두개를 만들겠습니다.<br>이미지의 특징을 추출해주니 꼭 신경망이 아니더라도 다른 분류기를(예를 들면 SVM 등) 사용하셔도 무방합니다.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model, Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications <span class="keyword">import</span> InceptionV3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fc 레이어를 포함하지 않고, imagenet기반으로 학습된 가중치를 로드한 뒤 GAP 레이어를 추가</span></span><br><span class="line">extractor = Sequential()</span><br><span class="line">extractor.add(InceptionV3(include_top=<span class="keyword">False</span>, weights=<span class="string">'imagenet'</span>, input_shape=IMG_SIZE))</span><br><span class="line">extractor.add(layers.GlobalAveragePooling2D())</span><br><span class="line"></span><br><span class="line">extractor_output_shape = extractor.get_output_shape_at(<span class="number">0</span>)[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(layers.InputLayer(input_shape=extractor_output_shape))</span><br><span class="line">model.add(layers.Dense(<span class="number">2</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 2)                 4098      
=================================================================
Total params: 4,098
Trainable params: 4,098
Non-trainable params: 0
_________________________________________________________________
</code></pre><h2 id="모델-컴파일"><a href="#모델-컴파일" class="headerlink" title="모델 컴파일"></a>모델 컴파일</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line">optimizer = Adam(lr=<span class="number">0.001</span>)</span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">    metrics=[<span class="string">'acc'</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">extractor.compile(</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">    metrics=[<span class="string">'acc'</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="특징-추출기-생성"><a href="#특징-추출기-생성" class="headerlink" title="특징 추출기 생성"></a>특징 추출기 생성</h2><p>이미지 제너레이터에서 특징을 추출하기 위한 펑션을 하나 만들어 줍니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_features</span><span class="params">(extractor, gen, cnt)</span>:</span></span><br><span class="line">    bs = gen.batch_size</span><br><span class="line">    ds = cnt</span><br><span class="line">    extractor_shapes = list(extractor.get_output_shape_at(<span class="number">0</span>)[<span class="number">1</span>:])</span><br><span class="line">    </span><br><span class="line">    features = np.empty([<span class="number">0</span>] + extractor_shapes)</span><br><span class="line">    labels = np.empty((<span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, (trainX, trainY) <span class="keyword">in</span> enumerate(gen):</span><br><span class="line">        features = np.append(features, extractor.predict(trainX), axis=<span class="number">0</span>)</span><br><span class="line">        labels = np.append(labels, trainY, axis=<span class="number">0</span>)</span><br><span class="line">        print(<span class="string">'batch index: &#123;&#125;/&#123;&#125;'</span>.format(i * bs, ds), end=<span class="string">'\r'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> bs * i &gt;= cnt:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    print()</span><br><span class="line">    <span class="keyword">return</span> features, labels</span><br></pre></td></tr></table></figure>
<h3 id="특징추출"><a href="#특징추출" class="headerlink" title="특징추출"></a>특징추출</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainX, trainY = get_features(extractor, trainGen, <span class="number">3000</span>)</span><br><span class="line">testX, testY = get_features(extractor, testGen, <span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<pre><code>batch index: 3000/3000
batch index: 1000/1000
</code></pre><h2 id="학습-시작"><a href="#학습-시작" class="headerlink" title="학습 시작"></a>학습 시작</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">    trainX, </span><br><span class="line">    trainY,</span><br><span class="line">    epochs=epochs,</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    validation_split=<span class="number">.1</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Train on 2718 samples, validate on 302 samples
Epoch 1/32
2718/2718 [==============================] - 2s 575us/step - loss: 0.3848 - acc: 0.8214 - val_loss: 0.2531 - val_acc: 0.8791
Epoch 2/32
2718/2718 [==============================] - 0s 95us/step - loss: 0.2236 - acc: 0.9031 - val_loss: 0.2380 - val_acc: 0.8891
Epoch 3/32
2718/2718 [==============================] - 0s 88us/step - loss: 0.1946 - acc: 0.9187 - val_loss: 0.2312 - val_acc: 0.8891
Epoch 4/32
2718/2718 [==============================] - 0s 88us/step - loss: 0.1733 - acc: 0.9284 - val_loss: 0.2322 - val_acc: 0.8907
Epoch 5/32
2718/2718 [==============================] - 0s 90us/step - loss: 0.1541 - acc: 0.9391 - val_loss: 0.2334 - val_acc: 0.8940
Epoch 6/32
2718/2718 [==============================] - 0s 93us/step - loss: 0.1441 - acc: 0.9430 - val_loss: 0.2444 - val_acc: 0.8957
Epoch 7/32
2718/2718 [==============================] - 0s 86us/step - loss: 0.1337 - acc: 0.9513 - val_loss: 0.2425 - val_acc: 0.8825
Epoch 8/32
2718/2718 [==============================] - 0s 88us/step - loss: 0.1295 - acc: 0.9507 - val_loss: 0.2432 - val_acc: 0.8940
Epoch 9/32
2718/2718 [==============================] - 0s 87us/step - loss: 0.1211 - acc: 0.9533 - val_loss: 0.2524 - val_acc: 0.8974
Epoch 10/32
2718/2718 [==============================] - 0s 90us/step - loss: 0.1143 - acc: 0.9573 - val_loss: 0.2539 - val_acc: 0.8924
Epoch 11/32
2718/2718 [==============================] - 0s 89us/step - loss: 0.1123 - acc: 0.9562 - val_loss: 0.2560 - val_acc: 0.8874
Epoch 12/32
2718/2718 [==============================] - 0s 85us/step - loss: 0.1009 - acc: 0.9639 - val_loss: 0.2659 - val_acc: 0.8940
Epoch 13/32
2718/2718 [==============================] - 0s 85us/step - loss: 0.0955 - acc: 0.9682 - val_loss: 0.2550 - val_acc: 0.8924
Epoch 14/32
2718/2718 [==============================] - 0s 91us/step - loss: 0.0901 - acc: 0.9673 - val_loss: 0.2738 - val_acc: 0.8940
Epoch 15/32
2718/2718 [==============================] - 0s 90us/step - loss: 0.0897 - acc: 0.9678 - val_loss: 0.2909 - val_acc: 0.8907
Epoch 16/32
2718/2718 [==============================] - 0s 87us/step - loss: 0.0843 - acc: 0.9722 - val_loss: 0.2811 - val_acc: 0.8891
Epoch 17/32
2718/2718 [==============================] - 0s 87us/step - loss: 0.0812 - acc: 0.9731 - val_loss: 0.2788 - val_acc: 0.8924
Epoch 18/32
2718/2718 [==============================] - 0s 90us/step - loss: 0.0800 - acc: 0.9737 - val_loss: 0.3198 - val_acc: 0.8891
Epoch 19/32
2718/2718 [==============================] - 0s 89us/step - loss: 0.0746 - acc: 0.9748 - val_loss: 0.2781 - val_acc: 0.8940
Epoch 20/32
2718/2718 [==============================] - 0s 85us/step - loss: 0.0759 - acc: 0.9748 - val_loss: 0.2898 - val_acc: 0.8924
Epoch 21/32
2718/2718 [==============================] - 0s 87us/step - loss: 0.0704 - acc: 0.9774 - val_loss: 0.2810 - val_acc: 0.8990
Epoch 22/32
2718/2718 [==============================] - 0s 88us/step - loss: 0.0660 - acc: 0.9792 - val_loss: 0.2831 - val_acc: 0.8940
Epoch 23/32
2718/2718 [==============================] - 0s 88us/step - loss: 0.0631 - acc: 0.9825 - val_loss: 0.2886 - val_acc: 0.8974
Epoch 24/32
2718/2718 [==============================] - 0s 89us/step - loss: 0.0611 - acc: 0.9827 - val_loss: 0.2841 - val_acc: 0.8990
Epoch 25/32
2718/2718 [==============================] - 0s 89us/step - loss: 0.0599 - acc: 0.9829 - val_loss: 0.2893 - val_acc: 0.8974
Epoch 26/32
2718/2718 [==============================] - 0s 89us/step - loss: 0.0575 - acc: 0.9845 - val_loss: 0.2965 - val_acc: 0.8990
Epoch 27/32
2718/2718 [==============================] - 0s 89us/step - loss: 0.0556 - acc: 0.9875 - val_loss: 0.2971 - val_acc: 0.9007
Epoch 28/32
2718/2718 [==============================] - 0s 90us/step - loss: 0.0531 - acc: 0.9860 - val_loss: 0.3044 - val_acc: 0.9007
Epoch 29/32
2718/2718 [==============================] - 0s 88us/step - loss: 0.0512 - acc: 0.9875 - val_loss: 0.3063 - val_acc: 0.8974
Epoch 30/32
2718/2718 [==============================] - 0s 87us/step - loss: 0.0498 - acc: 0.9893 - val_loss: 0.3097 - val_acc: 0.8990
Epoch 31/32
2718/2718 [==============================] - 0s 91us/step - loss: 0.0499 - acc: 0.9880 - val_loss: 0.3155 - val_acc: 0.8924
Epoch 32/32
2718/2718 [==============================] - 0s 94us/step - loss: 0.0463 - acc: 0.9904 - val_loss: 0.3197 - val_acc: 0.8957
</code></pre><h2 id="결과-시각화"><a href="#결과-시각화" class="headerlink" title="결과 시각화"></a>결과 시각화</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_graph</span><span class="params">(history_dict)</span>:</span></span><br><span class="line">    accuracy = history_dict[<span class="string">'acc'</span>]</span><br><span class="line">    val_accuracy = history_dict[<span class="string">'val_acc'</span>]</span><br><span class="line">    loss = history_dict[<span class="string">'loss'</span>]</span><br><span class="line">    val_loss = history_dict[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">    epochs = range(<span class="number">1</span>, len(loss) + <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">121</span>)</span><br><span class="line">    plt.subplots_adjust(top=<span class="number">2</span>)</span><br><span class="line">    plt.plot(epochs, accuracy, <span class="string">'ro'</span>, label=<span class="string">'Training accuracy'</span>)</span><br><span class="line">    plt.plot(epochs, val_accuracy, <span class="string">'r'</span>, label=<span class="string">'Validation accuracy'</span>)</span><br><span class="line">    plt.title(<span class="string">'Trainging and validation accuracy'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">'upper center'</span>, bbox_to_anchor=(<span class="number">0.5</span>, <span class="number">-0.1</span>),</span><br><span class="line">              fancybox=<span class="keyword">True</span>, shadow=<span class="keyword">True</span>, ncol=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">122</span>)</span><br><span class="line">    plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">    plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">    plt.legend(loc=<span class="string">'upper center'</span>, bbox_to_anchor=(<span class="number">0.5</span>, <span class="number">-0.1</span>),</span><br><span class="line">          fancybox=<span class="keyword">True</span>, shadow=<span class="keyword">True</span>, ncol=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">.8</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            previous = smoothed_points[<span class="number">-1</span>]</span><br><span class="line">            smoothed_points.append(previous * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_graph(history.history)</span><br></pre></td></tr></table></figure>
<p><img src="transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_16_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">smooth_data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key, val <span class="keyword">in</span> history.history.items():</span><br><span class="line">    smooth_data[key] = smooth_curve(val[:])</span><br><span class="line">show_graph(smooth_data)</span><br></pre></td></tr></table></figure>
<p><img src="transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_17_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(testX, testY)</span><br></pre></td></tr></table></figure>
<pre><code>1020/1020 [==============================] - 0s 59us/step





[0.16686982696547228, 0.9480392149850434]
</code></pre><p>imagenet으로 학습한 모델을 이용했을 때 이미지의 분류를 위한 특징을 잘 뽑아내도록 필터가 학습되어 있으므로,<br>첫 에폭에서부터 높은 결과를 보여주는걸 확인할 수 있습니다.  </p>
<h1 id="Fine-Tuning"><a href="#Fine-Tuning" class="headerlink" title="Fine Tuning"></a>Fine Tuning</h1><p>Find Tuning이란 미세조정인데요.<br>아무래도 기존 학습된 네트워크는 학습한 데이터셋에 잘맞도록 학습이 되어 있겠죠.<br>그렇다고 우리 데이터셋으로 밑바닥부터 학습시키기엔 데이터를 모으기가 힘든 경우가 대다수입니다.<br>이런 경우에 학습된 네트워크를 미세조정하여 우리의 데이터셋에 조금 더 잘 맞도록 모델의 파라메터를 조정하는 과정을 거치는데요.<br>이 과정을 Fine Tuning이라고 합니다.  </p>
<p>하지만 연산량이 많아지기 때문에 위의 Transfer Learning보다 상대적으로 시간이 조금 더 필요하게 됩니다.<br>Fine Tuning은 CPU로 하기엔 연산량이 많아 <strong>GPU 사용을 권장</strong>합니다.</p>
<p><strong>미세조정의 순서는 대략 아래와 같습니다.</strong></p>
<ol>
<li>분류기를 학습한다. (이때 분류기를 제외한 모델의 모든 레이어는 가중치를 업데이트 되지 않도록 <strong>동결(Freeze)</strong> 시킵니다)  </li>
<li>모델의 마지막 레이어들을 미세조정을 실시한다.  </li>
</ol>
<p>이렇게 먼저 분류기를 학습하는 이유는 저희가 추가한 분류기의 가중치는 랜덤하게 초기화가 되어 있습니다.<br>이러한 분류기를 통해 그대로 보틀넥 레이어를 재학습 할 경우, Loss가 높아 기존의 레이어가 망가질 우려가 있습니다.<br>기존 학습된 모델의 가중치를 최대한 미세하게 조정하기 위하여 분류기를 선학습 한 이후, 보틀넥 레이어를 다시 재학습 하도록 합니다.</p>
<p>가장 중요한 부분은 모델의 가중치 동결인데요.<br>기존 학습된 모델의 경우 앞의 레이어들은 이미지를 직관적으로 이해할 수 있도록 이미지 자체의 엣지 디텍터등의 역할을 수행합니다.<br>레이어가 뒤로 향할수록 필터에 대한 데이터를 추상적으로 표현하게 되는데, 앞단의 레이어들의 가중치를 동결함으로써 학습 시 필터의 역할이 망가지지 않도록 하는 역할을 합니다.</p>
<h2 id="데이터셋-준비-1"><a href="#데이터셋-준비-1" class="headerlink" title="데이터셋 준비"></a>데이터셋 준비</h2><p>위에서 사용한 제너레이터를 조금 변경하여 사용하도록 하겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">rootPath = <span class="string">'./datasets/cat-and-dog'</span></span><br><span class="line"></span><br><span class="line">IMG_SIZE = (<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)  </span><br><span class="line">imageGenerator = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">20</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">    brightness_range=[<span class="number">.2</span>, <span class="number">.2</span>],</span><br><span class="line">    horizontal_flip=<span class="keyword">True</span>,</span><br><span class="line">    validation_split=<span class="number">0.1</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainGen = imageGenerator.flow_from_directory(</span><br><span class="line">    os.path.join(rootPath, <span class="string">'training_set'</span>),</span><br><span class="line">    target_size=IMG_SIZE[:<span class="number">2</span>],</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    subset=<span class="string">'training'</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">validationGen = imageGenerator.flow_from_directory(</span><br><span class="line">    os.path.join(rootPath, <span class="string">'training_set'</span>),</span><br><span class="line">    target_size=IMG_SIZE[:<span class="number">2</span>],</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    subset=<span class="string">'validation'</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">testGen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">).flow_from_directory(</span><br><span class="line">    os.path.join(rootPath, <span class="string">'test_set'</span>),</span><br><span class="line">    target_size=IMG_SIZE[:<span class="number">2</span>],</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Found 7205 images belonging to 2 classes.
Found 800 images belonging to 2 classes.
Found 2023 images belonging to 2 classes.
</code></pre><h2 id="모델-구성-1"><a href="#모델-구성-1" class="headerlink" title="모델 구성"></a>모델 구성</h2><p>위에서 사용한 InceptionV3 모델을 이용해도 되지만, 저희는 새로운 모델을 만들어 진행해보겠습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">inception = InceptionV3(include_top=<span class="keyword">False</span>, weights=<span class="string">'imagenet'</span>, input_shape=IMG_SIZE)</span><br><span class="line">gap = layers.GlobalAveragePooling2D()(inception.output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 마지막 31번째 뒤 레이어들을 제외한 모든 레이어를 가중치 동결합니다.</span></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> inception.layers[:<span class="number">-31</span>]:</span><br><span class="line">    l.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 위의 Transfer Learning에서 훈련시킨 분류기를 이용합니다.</span></span><br><span class="line">classifier = model</span><br><span class="line"></span><br><span class="line">model = Model(inception.input, classifier(gap))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 150, 150, 3)  0                                            
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_3[0][0]                    
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              



                                      중간 생략 ...


__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             
                                                                 activation_186[0][0]             
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_3[0][0]              
                                                                 activation_187[0][0]             
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    
__________________________________________________________________________________________________
sequential_1 (Sequential)       (None, 2)            4098        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 21,806,882
Trainable params: 6,077,634
Non-trainable params: 15,729,248
__________________________________________________________________________________________________
</code></pre><p>모델의 구성을 잘 보시면 총 파라메터의 개수는 약 2,200만개의 파라메터를 가지고 있지만,<br>훈련이 가능한 파라메터의 수는 약 600만개 입니다.<br>나머지 1,500만개의 파라메터는 저희가 설정한대로 가중치 업데이트가 동결 되었습니다.</p>
<h2 id="모델-컴파일-1"><a href="#모델-컴파일-1" class="headerlink" title="모델 컴파일"></a>모델 컴파일</h2><p>모델의 미세조정을 위해 러닝레이트를 줄여 학습을 진행합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">optimizer = Adam(lr=<span class="number">0.0001</span>)</span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=optimizer,</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">    metrics=[<span class="string">'acc'</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="학습-시작-1"><a href="#학습-시작-1" class="headerlink" title="학습 시작"></a>학습 시작</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">32</span></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    generator=trainGen,</span><br><span class="line">    epochs=epochs,</span><br><span class="line">    steps_per_epoch=trainGen.n / trainGen.batch_size,</span><br><span class="line">    validation_data=validationGen,</span><br><span class="line">    validation_steps=validationGen.n / validationGen.batch_size,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/32
226/225 [==============================] - 57s 253ms/step - loss: 0.2900 - acc: 0.8724 - val_loss: 0.3690 - val_acc: 0.9169
Epoch 2/32
226/225 [==============================] - 55s 245ms/step - loss: 0.2683 - acc: 0.8868 - val_loss: 0.4129 - val_acc: 0.9081
Epoch 3/32
226/225 [==============================] - 56s 246ms/step - loss: 0.2487 - acc: 0.8915 - val_loss: 0.4223 - val_acc: 0.9081
Epoch 4/32
226/225 [==============================] - 56s 246ms/step - loss: 0.2156 - acc: 0.9079 - val_loss: 0.4608 - val_acc: 0.9131
Epoch 5/32
226/225 [==============================] - 55s 244ms/step - loss: 0.2214 - acc: 0.9061 - val_loss: 0.3838 - val_acc: 0.9144
Epoch 6/32
226/225 [==============================] - 55s 243ms/step - loss: 0.1986 - acc: 0.9154 - val_loss: 0.4782 - val_acc: 0.9019
Epoch 7/32
226/225 [==============================] - 55s 245ms/step - loss: 0.1875 - acc: 0.9258 - val_loss: 0.3910 - val_acc: 0.9313
Epoch 8/32
226/225 [==============================] - 55s 243ms/step - loss: 0.1663 - acc: 0.9322 - val_loss: 0.4091 - val_acc: 0.9250
Epoch 9/32
226/225 [==============================] - 55s 241ms/step - loss: 0.1813 - acc: 0.9256 - val_loss: 0.5089 - val_acc: 0.9163
Epoch 10/32
226/225 [==============================] - 55s 244ms/step - loss: 0.1742 - acc: 0.9275 - val_loss: 0.4822 - val_acc: 0.9094
Epoch 11/32
226/225 [==============================] - 55s 242ms/step - loss: 0.1580 - acc: 0.9341 - val_loss: 0.4449 - val_acc: 0.9137
Epoch 12/32
226/225 [==============================] - 56s 247ms/step - loss: 0.1556 - acc: 0.9375 - val_loss: 0.5008 - val_acc: 0.9163
Epoch 13/32
226/225 [==============================] - 55s 243ms/step - loss: 0.1676 - acc: 0.9314 - val_loss: 0.4137 - val_acc: 0.9087
Epoch 14/32
226/225 [==============================] - 55s 244ms/step - loss: 0.1466 - acc: 0.9375 - val_loss: 0.6155 - val_acc: 0.8925
Epoch 15/32
226/225 [==============================] - 55s 244ms/step - loss: 0.1364 - acc: 0.9459 - val_loss: 0.5151 - val_acc: 0.9125
Epoch 16/32
226/225 [==============================] - 55s 243ms/step - loss: 0.1325 - acc: 0.9458 - val_loss: 0.5785 - val_acc: 0.9025
Epoch 17/32
226/225 [==============================] - 56s 246ms/step - loss: 0.1303 - acc: 0.9496 - val_loss: 0.5260 - val_acc: 0.9081
Epoch 18/32
226/225 [==============================] - 55s 242ms/step - loss: 0.1337 - acc: 0.9463 - val_loss: 0.5409 - val_acc: 0.9106
Epoch 19/32
226/225 [==============================] - 56s 247ms/step - loss: 0.1189 - acc: 0.9550 - val_loss: 0.4270 - val_acc: 0.9181
Epoch 20/32
226/225 [==============================] - 55s 245ms/step - loss: 0.1166 - acc: 0.9532 - val_loss: 0.5129 - val_acc: 0.9250
Epoch 21/32
226/225 [==============================] - 55s 244ms/step - loss: 0.1117 - acc: 0.9556 - val_loss: 0.7072 - val_acc: 0.8981
Epoch 22/32
226/225 [==============================] - 56s 247ms/step - loss: 0.1155 - acc: 0.9562 - val_loss: 0.4914 - val_acc: 0.9187
Epoch 23/32
226/225 [==============================] - 56s 247ms/step - loss: 0.1055 - acc: 0.9602 - val_loss: 0.6032 - val_acc: 0.9006
Epoch 24/32
226/225 [==============================] - 55s 246ms/step - loss: 0.1140 - acc: 0.9549 - val_loss: 0.4621 - val_acc: 0.9044
Epoch 25/32
226/225 [==============================] - 55s 244ms/step - loss: 0.1158 - acc: 0.9532 - val_loss: 0.5440 - val_acc: 0.9144
Epoch 26/32
226/225 [==============================] - 55s 241ms/step - loss: 0.1042 - acc: 0.9628 - val_loss: 0.5088 - val_acc: 0.9100
Epoch 27/32
226/225 [==============================] - 55s 245ms/step - loss: 0.0982 - acc: 0.9605 - val_loss: 0.5012 - val_acc: 0.9200
Epoch 28/32
226/225 [==============================] - 55s 242ms/step - loss: 0.1063 - acc: 0.9577 - val_loss: 0.5262 - val_acc: 0.9056
Epoch 29/32
226/225 [==============================] - 55s 241ms/step - loss: 0.0933 - acc: 0.9637 - val_loss: 0.4498 - val_acc: 0.9294
Epoch 30/32
226/225 [==============================] - 54s 241ms/step - loss: 0.0916 - acc: 0.9658 - val_loss: 0.5562 - val_acc: 0.9044
Epoch 31/32
226/225 [==============================] - 55s 244ms/step - loss: 0.0870 - acc: 0.9666 - val_loss: 0.4454 - val_acc: 0.9169
Epoch 32/32
226/225 [==============================] - 55s 245ms/step - loss: 0.0857 - acc: 0.9660 - val_loss: 0.5616 - val_acc: 0.9119
</code></pre><h2 id="모델-평가-및-시각화"><a href="#모델-평가-및-시각화" class="headerlink" title="모델 평가 및 시각화"></a>모델 평가 및 시각화</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate_generator(testGen)</span><br></pre></td></tr></table></figure>
<pre><code>[0.2855920347539756, 0.95551161632288]
</code></pre><p>테스트셋에 위의 분류기보다 조금 더 높은 정확도를 확인할 수 있습니다.<br>정학도가 높아질수록 정확도 1% 올리는게 더더욱 힘들어지죠</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_graph(history.history)</span><br></pre></td></tr></table></figure>
<p><img src="transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_33_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">smooth_data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key, val <span class="keyword">in</span> history.history.items():</span><br><span class="line">    smooth_data[key] = smooth_curve(val[:])</span><br><span class="line">show_graph(smooth_data)</span><br></pre></td></tr></table></figure>
<p><img src="transfer-learning-and-find-tuning_files/transfer-learning-and-find-tuning_34_0.png" alt="png"></p>
<p>5~10에폭에서부터 과대적합이 시작되는것처럼 보이는데요.<br>이 예제에서는 분류기를 이전에 학습한걸 그대로 사용하였으나, 여러가지 방법으로 테스트를 진행해보세요.</p>

      
    </div>
    <footer class="article-footer">
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Rogiry
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/2019/01/22/transfer-learning-and-find-tuning/" target="_blank" title="딥러닝으로 개와 고양이를 분류해보자 - 전이학습과 미세조정">https://codingcrews.github.io/2019/01/22/transfer-learning-and-find-tuning/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>
</div></div>
      
      
        
	<section id="comments" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'codingcrews';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>



      
      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2019/01/19/cat-dog-resnet/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">딥러닝으로 개와 고양이를 분류하는 모델을 만들어보자 - ResNet50</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Transfer-Learning-amp-Find-Tuning"><span class="nav-number">1.</span> <span class="nav-text">Transfer Learning &amp; Find Tuning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Feature-Extraction"><span class="nav-number">2.</span> <span class="nav-text">Feature Extraction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#데이터셋-준비"><span class="nav-number">2.1.</span> <span class="nav-text">데이터셋 준비</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#모델-구성"><span class="nav-number">2.2.</span> <span class="nav-text">모델 구성</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#모델-컴파일"><span class="nav-number">2.3.</span> <span class="nav-text">모델 컴파일</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#특징-추출기-생성"><span class="nav-number">2.4.</span> <span class="nav-text">특징 추출기 생성</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#특징추출"><span class="nav-number">2.4.1.</span> <span class="nav-text">특징추출</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#학습-시작"><span class="nav-number">2.5.</span> <span class="nav-text">학습 시작</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#결과-시각화"><span class="nav-number">2.6.</span> <span class="nav-text">결과 시각화</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Fine-Tuning"><span class="nav-number">3.</span> <span class="nav-text">Fine Tuning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#데이터셋-준비-1"><span class="nav-number">3.1.</span> <span class="nav-text">데이터셋 준비</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#모델-구성-1"><span class="nav-number">3.2.</span> <span class="nav-text">모델 구성</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#모델-컴파일-1"><span class="nav-number">3.3.</span> <span class="nav-text">모델 컴파일</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#학습-시작-1"><span class="nav-number">3.4.</span> <span class="nav-text">학습 시작</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#모델-평가-및-시각화"><span class="nav-number">3.5.</span> <span class="nav-text">모델 평가 및 시각화</span></a></li></ol></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2019 - 2019 CodingCrew All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>



<!-- Google Analytics -->
<!-- <script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-132432701-1', 'auto');
  ga('send', 'pageview');

</script> -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-132432701-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-132432701-1');
</script>
<!-- End Google Analytics -->






	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">설정</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              글자크기
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            페이지 글자 크기를 조정하였습니다
          </div>
        </div>




          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              야간 모드
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            다시 클릭하여 야간모드를 해제할 수 있습니다.
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;정 보&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            CodingCrew
          </div>
          <div class="panel-body">
            Copyright © 2019 Rogiry All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>

  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>